{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "from vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \n",
    "dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_551332/2406001790.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(_URL))\n"
     ]
    }
   ],
   "source": [
    "model = VGGT()\n",
    "_URL = \"./model.pt\"\n",
    "model.load_state_dict(torch.load(_URL))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_551332/3590608388.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=dtype):\n"
     ]
    }
   ],
   "source": [
    "path = \"./test_model/black_and_mx\"\n",
    "\n",
    "image_names = sorted(glob.glob(os.path.join(path, \"*.png\")))\n",
    "images = load_and_preprocess_images(image_names).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(dtype=dtype):\n",
    "        images = images[None]  # add batch dimension\n",
    "        aggregated_tokens_list, ps_idx = model.aggregator(images)\n",
    "                \n",
    "    # Predict Cameras\n",
    "    pose_enc = model.camera_head(aggregated_tokens_list)[-1]\n",
    "    # Extrinsic and intrinsic matrices, following OpenCV convention (camera from world)\n",
    "    extrinsic, intrinsic = pose_encoding_to_extri_intri(pose_enc, images.shape[-2:])\n",
    "\n",
    "    # Predict Depth Maps\n",
    "    depth_map, depth_conf = model.depth_head(aggregated_tokens_list, images, ps_idx)\n",
    "\n",
    "    # Predict Point Maps\n",
    "    point_map, point_conf = model.point_head(aggregated_tokens_list, images, ps_idx)\n",
    "        \n",
    "    # Construct 3D Points from Depth Maps and Cameras\n",
    "    # which usually leads to more accurate 3D points than point map branch\n",
    "    point_map_by_unprojection = unproject_depth_map_to_point_map(depth_map.squeeze(0), \n",
    "                                                                extrinsic.squeeze(0), \n",
    "                                                                intrinsic.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面保存一些TSDF fusion需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3328097"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(depth_conf.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_select = depth_conf < 2.34\n",
    "depth_map[depth_select] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"depth_map.npy\",depth_map[0].cpu().numpy())\n",
    "# np.save(\"depth_conf.npy\",depth_conf[0].cpu().numpy())\n",
    "np.save(\"extrinsic.npy\",extrinsic[0].cpu().numpy())\n",
    "np.save(\"intrinsic.npy\",intrinsic[0].cpu().numpy())\n",
    "np.save(\"images.npy\",images[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_all = point_map_by_unprojection.reshape(-1, 3)\n",
    "color_all = images[0].permute(0, 2, 3, 1).reshape(-1, 3).detach().cpu().numpy()\n",
    "conf_all = depth_conf[0].reshape(-1,).detach().cpu().numpy()\n",
    "threshold = np.median(conf_all)\n",
    "conf_mask = conf_all > threshold\n",
    "point_all = point_all[conf_mask]\n",
    "color_all = color_all[conf_mask]\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_all)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_all)\n",
    "\n",
    "o3d.io.write_point_cloud(\"pointcloud.ply\", pcd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
